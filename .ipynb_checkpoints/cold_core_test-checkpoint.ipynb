{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import iris.quickplot as qplt\n",
    "import iris.plot as iplt\n",
    "import datetime\n",
    "import shutil\n",
    "from six.moves import urllib\n",
    "from pathlib import Path\n",
    "import trackpy\n",
    "from iris.time import PartialDateTime\n",
    "\n",
    "import tobac #tobac package cloned from https://github.com/tobac-project/tobac.git\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, append=True)\n",
    "warnings.filterwarnings('ignore', category=pd.io.pytables.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/users/hgilmour/olr/olr_1h/2005/olr_merge_jan_2005.nc\n",
      "toa_outgoing_longwave_flux / (W m-2) (time: 744; latitude: 1360; longitude: 1360)\n",
      "    Dimension coordinates:\n",
      "        time                              x              -                -\n",
      "        latitude                          -              x                -\n",
      "        longitude                         -              -                x\n",
      "    Auxiliary coordinates:\n",
      "        forecast_period                   x              -                -\n",
      "    Scalar coordinates:\n",
      "        forecast_reference_time      2002-01-01 00:00:00\n",
      "    Cell methods:\n",
      "        mean                         time (1 hour)\n",
      "    Attributes:\n",
      "        Conventions                  'CF-1.7'\n",
      "        STASH                        m01s03i332\n",
      "        source                       'Data from Met Office Unified Model'\n",
      "        um_version                   '10.6'\n",
      "[[3451.3477 3451.3477 3451.3477 ... 3451.3477 3451.3477 3451.3477]\n",
      " [3453.3967 3453.3967 3453.3967 ... 3453.3967 3453.3967 3453.3967]\n",
      " [3455.4443 3455.4443 3455.4443 ... 3455.4443 3455.4443 3455.4443]\n",
      " ...\n",
      " [4356.1074 4356.1074 4356.1074 ... 4356.1074 4356.1074 4356.1074]\n",
      " [4355.286  4355.286  4355.286  ... 4355.286  4355.286  4355.286 ]\n",
      " [4354.4624 4354.4624 4354.4624 ... 4354.4624 4354.4624 4354.4624]]\n",
      "[[4508.4844 4508.4844 4508.4844 ... 4508.4844 4508.4844 4508.4844]\n",
      " [4508.4844 4508.4844 4508.4844 ... 4508.4844 4508.4844 4508.4844]\n",
      " [4508.272  4508.272  4508.272  ... 4508.272  4508.272  4508.272 ]\n",
      " ...\n",
      " [4508.4844 4508.4844 4508.4844 ... 4508.4844 4508.4844 4508.4844]\n",
      " [4508.4844 4508.4844 4508.4844 ... 4508.4844 4508.4844 4508.4844]\n",
      " [4508.4844 4508.4844 4508.4844 ... 4508.4844 4508.4844 4508.4844]]\n"
     ]
    }
   ],
   "source": [
    "#load in file\n",
    "data_out=('../')\n",
    "data_file = '/data/users/hgilmour/olr/olr_1h/2005/olr_merge_jan_2005.nc' #this is the 1 hourly mean olr data for the first 20 days of 1998\n",
    "print(data_file)\n",
    "\n",
    "olr=iris.load_cube(data_file)\n",
    "\n",
    "\n",
    "#constraining the dataset by time so it runs quicker: \n",
    "#week=iris.Constraint(time=lambda cell: cell.point.day<=7) #just the first 7 days\n",
    "#olr = olr.extract(week)\n",
    "\n",
    "olr.coord('time').bounds=None #REMOVING BOUNDS FROM TIME TO SEE IF THIS HELPS THE TYPEERROR\n",
    "# Remove coord system or else the animations don't run (suggested by AVD team)\n",
    "olr.coord('latitude').coord_system = None\n",
    "olr.coord('longitude').coord_system = None\n",
    "\n",
    "#code that AVD team sent:\n",
    "time = olr.coord('time')\n",
    "datetimes = time.units.num2date(time.points)\n",
    "con = iris.Constraint(time=datetimes[0])\n",
    "olr.extract(con)\n",
    "\n",
    "\n",
    "print(olr)\n",
    "\n",
    "#Set up directory to save output and plots:\n",
    "savedir=Path(\"Save\")\n",
    "if not savedir.is_dir():\n",
    "    savedir.mkdir()\n",
    "plot_dir=Path(\"Plot\")\n",
    "if not plot_dir.is_dir():\n",
    "    plot_dir.mkdir()      \n",
    "\n",
    "\n",
    "#calculating dxy\n",
    "from math import pi\n",
    "longitude,latitude=np.meshgrid(olr.coord('longitude').points,olr.coord('latitude').points)\n",
    "R=6.3781e6\n",
    "dx=np.gradient(longitude)[1]\n",
    "dx=dx*(pi/180)*R*np.cos(latitude*pi/180)\n",
    "dy=np.gradient(latitude)[0]\n",
    "dy=dy*(pi/180)*R\n",
    "print(dx)\n",
    "print(dy)\n",
    "\n",
    "\n",
    "# Determine temporal and spatial sampling of the input data:\n",
    "dxy,dt=tobac.get_spacings(olr,grid_spacing=4500,time_spacing=3600) #time spacing = 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxy,dt=tobac.get_spacings(olr,grid_spacing=4500,time_spacing=3600) #time spacing = 1 hour\n",
    "\n",
    "\n",
    "#Convert from olr to Tb using Ohring and Gruber empirical formula:\n",
    "# # (1984) as given in Yang and Slingo (2001)\n",
    "    # Tf = tb(a+b*Tb) where a = 1.228 and b = -1.106e-3 K^-1\n",
    "    # OLR = sigma*Tf^4 \n",
    "    # where sigma = Stefan-Boltzmann constant = 5.67x10^-8 W m^-2 K^-4\n",
    "a = 1.228\n",
    "b = -1.106e-3\n",
    "sigma = 5.67e-8 # W m^-2 K^-4\n",
    "\n",
    "tf = (olr.data/5.67e-8)**0.25\n",
    "tb_var = (-1.228 + np.sqrt(1.228**2 + 4*-1.106e-3*tf.data))/(2*-1.106e-3)\n",
    "\n",
    "tb=olr.copy()\n",
    "tb.data=tb_var.data\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter features:\n",
    "parameters_features={}\n",
    "parameters_features['position_threshold']='weighted_diff'\n",
    "parameters_features['sigma_threshold']=0.5\n",
    "parameters_features['target']='minimum'\n",
    "parameters_features['threshold']=[240,225,210,200,190] #olr threshold equivalent to Tb=225K based on stefan boltzmann equation (145 for 225K, 91 for 200K, 74 for 190K)\n",
    "parameters_features['n_min_threshold']=1975 # number of grid points for 40,000km^2 area (7792m = 1 grid space. 4500m x 4500m = 20250000m^2. 40,000km^2 = 4x10^10m^2. 4x10^10 / 20250000 = 1975 (1975 grid cells per 40,000km^2 area)\n",
    "\n",
    "# Feature detection and save results to file:\n",
    "print('starting feature detection')\n",
    "Features=tobac.feature_detection_multithreshold(tb,dxy,**parameters_features)\n",
    "Features.to_hdf('Save/cold_core/Features.h5','table')\n",
    "print('feature detection performed and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation:\n",
    "parameters_segmentation={}\n",
    "parameters_segmentation['target']='minimum'\n",
    "parameters_segmentation['method']='watershed'\n",
    "parameters_segmentation['threshold']=240\n",
    "\n",
    "\n",
    "# Perform segmentation and save results to files:\n",
    "Mask_tb,Features_tb=tobac.segmentation_2D(Features,tb,dxy,**parameters_segmentation)\n",
    "print('segmentation tb performed, start saving results to files')\n",
    "iris.save([Mask_tb], savedir / 'Mask_Segmentation_tb.nc', zlib=True, complevel=4)\n",
    "Features_tb.to_hdf('Save/cold_core/Features_tb.h5', 'table')\n",
    "print('segmentation tb performed and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linking:\n",
    "parameters_linking={}\n",
    "parameters_linking['v_max']=60 #(velocity of 60 m s-1 is referenced in https://journals.ametsoc.org/view/journals/mwre/126/6/1520-0493_1998_126_1630_lcvomc_2.0.co_2.xml#i1520-0493-126-6-1630-f01 study)\n",
    "parameters_linking['stubs']=7 #minimum number of timesteps for a tracked cell to be reported (equivalent to 6 hours)\n",
    "parameters_linking['order']=1\n",
    "parameters_linking['extrapolate']=0 \n",
    "parameters_linking['memory']=0\n",
    "parameters_linking['adaptive_stop']=0.2\n",
    "parameters_linking['adaptive_step']=0.95\n",
    "parameters_linking['subnetwork_size']=15\n",
    "parameters_linking['method_linking']= 'predict'\n",
    "\n",
    "\n",
    "\n",
    "# Perform linking and save results to file:\n",
    "Track=tobac.linking_trackpy(Features,tb,dt=dt,dxy=dxy,**parameters_linking)\n",
    "Track[\"longitude\"]=Track[\"longitude\"]-360\n",
    "Track.to_hdf('Save/cold_core/Track.h5','table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Track = pd.read_hdf('Save/cold_core/Track.h5','table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556   unique cloud cells in month Jan 2005. Features: 11424\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(Track.cell.values).shape[0], '  unique cloud cells in month Jan 2005. Features:', Track.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556\n"
     ]
    }
   ],
   "source": [
    "print(len(Track['cell'].dropna().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_core=[225,210,200,190]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.unique(Track.cell.values):\n",
    "    subset = Track[Track.cell == i]\n",
    "    for i in cold_core:\n",
    "        if subset[subset.threshold_value <=i].shape[0] == 0:\n",
    "            Track.drop(Track.loc[Track['cell']== i].index, inplace=True)\n",
    "            Track.to_hdf('Save/cold_core/Track_coldcore_{0}.h5'.format(i), 'table')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(Track.cell.values).shape[0], '  unique cloud cells in month Jan 2005. Features:', Track.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Track_225 = pd.read_hdf('Save/cold_core/Track_coldcore_225.h5','table')\n",
    "Track_210 = pd.read_hdf('Save/cold_core/Track_coldcore_210.h5','table')\n",
    "Track_200 = pd.read_hdf('Save/cold_core/Track_coldcore_200.h5','table')\n",
    "Track_190 = pd.read_hdf('Save/cold_core/Track_coldcore_190.h5','table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "axis_extent=[-80,-30,-35,12]\n",
    "\n",
    "#loop for each timestep:\n",
    "plt.figure()\n",
    "\n",
    "fig_map,ax_map=plt.subplots(figsize=(30,28),subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ax_map.set_extent([-85,-30,-40,10])\n",
    "plt.plot(Track_225['longitude'],Track_225['latitude'], '-',linewidth=5,color='k')\n",
    "plt.plot(Track_190['longitude'],Track_225['latitude'], '-',linewidth=5,color='k')\n",
    "plt.xticks([-80,-70,-60,-50,-40,-30],fontsize=30)\n",
    "plt.yticks([-40,-30,-20,-10,0,10],fontsize=30)\n",
    "plt.gca().coastlines()\n",
    "plt.xlabel('Lon $^\\circ$E', fontsize=40)\n",
    "plt.ylabel('Lat $^\\circ$N', fontsize=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-myclone Python (Conda)",
   "language": "python",
   "name": "conda-env-.conda-myclone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
